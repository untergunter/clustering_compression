{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Text_generator.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyPVt4oYvVW70ay6YpNDvFeF"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"U7246xUZbrGE"},"source":["# loading the text"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9zNIxyg8pzMT","executionInfo":{"status":"ok","timestamp":1620062980836,"user_tz":-180,"elapsed":592,"user":{"displayName":"יוסי גבריאל","photoUrl":"","userId":"07461216696072158750"}},"outputId":"743b25f6-e5e4-4fed-c376-02605c3dcbf6"},"source":["from google.colab import drive\n","\n","drive.mount('/content/drive')\n","\n","# learning\n","learning_file_path = \"wonderland.txt\"\n","saving_weights_path = '/content/drive/MyDrive/semes_2/semester_2/advenced_mechine_learning/ex3/weights/'\n","\n","# generating\n","generating_file_path = \"wonderland.txt\"\n","weights_file_path = \"/content/drive/MyDrive/semes_2/semester_2/advenced_mechine_learning/ex3/weights/weights-improvement-50-1.0240-bigger.hdf5\""],"execution_count":23,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"dSAy8n0tbPyX","executionInfo":{"status":"ok","timestamp":1620052571255,"user_tz":-180,"elapsed":1307,"user":{"displayName":"יוסי גבריאל","photoUrl":"","userId":"07461216696072158750"}}},"source":["text = 'Temperatures were measured with TAT-2000 and TAT-5000 TemporalScanner thermometers (Exergen Corp, Watertown, MA) and the Athena Elevated Temperature Detection System (Athena Security, Austin, TX). Exergen reports their instruments to be accurate within 0.2°C and 0.1°C, respectively.3,4 The Athena telethermographic system uses artificial intelligence to detect human faces by measuring the temperature of multiple points on the face relative to a blackbody temperature reference source.5 According to Athena Security, the system is accurate within 0.3°C.5 Systems were purchased from Athena Security. Accepting manufacturer specifications, detecting 0.2°C difference between devices (assuming standard deviation of ±0.3°C) required 26 measurements from each device. One subject was measured 104 times with 4 different TAT-2000s (26 measurements per device) and 104 times with 4 different TAT-5000s (26 measurements per device) by a single operator, and 13 times with the Athena system at a single location within 90 minutes to minimize subject and environmental temperature variation. We repeated measurements with the same subject and thermometer operator at a second location with 3 additional TAT-5000s, 1 TAT-5000 used previously (104 measurements, 26 per device) and a second thermal camera (13 measurements). We simulated fever using air-activated hand warmers (HotHands, Kobayashi Americas, Dalton, GA) held to the forehead. Descriptive statistical analyses were performed with Stata version 15 SE software (StataCorp, College Station, TX). Summaries were reported as means with 95% confidence intervals and differences were tested by 1-way ANOVA. A 2-sided P < .05 was considered statistically significant. During the first session, the TAT-2000s measured higher temperatures [mean, 98.3°F (95% CI, 98.2–98.3) or 36.8°C (95% CI, 36.8–36.8)] than the TAT-5000s [mean, 97.8 °F (95% CI, 97.8–97.9) or 36.6°C (95% CI, 36.5–36.6)] or the Athena system [mean, 97.9°F (95% CI, 97.8–98.0) or 36.6°C (95% CI, 36.5–36.7)] (P < .05). There was no significant difference between the TAT-5000s and the Athena system [mean difference, −0.07°F (95% CI, −0.23 to 0.09) or −0.04°C (95% CI, −0.13 to 0.05)], but the TAT-2000s measured temperatures significantly higher than the Athena [mean difference, 0.40°F (95% CI, 0.24–0.56) or 0.22°C (95% CI, 0.13–0.31)]. During the second testing session, the TAT-5000s measured 0.34°F (95% CI, 0.20–0.48) or 0.19°C (95% CI, 0.11–0.26) [mean, 98.1°F (95% CI, 98.1–98.2) or 36.7°C (95% CI, 36.7–36.8)] higher than the Athena system [mean, 97.8°F (95% CI, 97.7–97.9) or 36.6°C (95% CI, 36.5–36.6)] (P < .05). HotHands warmers reached up to 46.1°C (115°F) 15–30 minutes after activation and were held at the forehead. A “symptomatic” individual in single-file line 6 feet (2 m) between “normal” individuals passing the camera at a rate of 1 individual per second, was detected in 8 of 8 attempts. Additionally, when the forehead was warmed and the warmer then removed, the Athena system was able to detect temperatures of >99°F or 37.2°C (Fig. 1) in 5 of 5 attempts. \\n\\n Screeners using TAT-5000s took a median of 16.5 seconds from the start of taking the temperature through cleaning the device until the thermometer was ready again. The Athena system has no effective delay from person to person passing in a single-file line. The COVID-19 pandemic has led to the implementation of temperature screening in a wide variety of facilities. Although temperature screening has been used in public settings during previous infectious diseases outbreaks,6–8 the usefulness of temperature screening to detect potential infections has been questioned.6,7 However, temperature screening may discourage symptomatic individuals from entering public places and may increase comfort for healthy people.8\\n Our study using noninvasive devices was not designed to test the accuracy of devices, though temporal scanners are widely considered reliable enough for professional use.9,10 In our use, temperatures measured by telethermographic systems were similar to those obtained by temporal scanners, suggesting similar performance. Cost is the biggest barrier to implementation for telethermographic systems. For our investment recovery analysis, we considered turnaround time difference between temporal scanners and a thermal camera for each screened individual at a high-entry location with large groups arriving in a short period, desired throughput rate of 1 person per second, maintaining 6-feet (2-m) social distancing and single-file lines for individual symptom screening. We estimated needing 6 temporal scanner operators for every 1 thermal camera operator. With our organization’s direct labor rates and overhead costs, investment recovery was estimated to occur in months, leading to adoption of 4 telethermographic systems at our 2 highest-entry locations. We reduced screening staff from 24 to 4 individuals, and there are now no waiting lines at these locations. In conclusion, our experience demonstrates that a telethermographic system improves screening throughput and reports temperatures similar to those recorded by temporal scanners, with acceptable investment recovery time.'"],"execution_count":8,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Sqvetg2XbsQO"},"source":["# Learning larger LSTM Network to Generate Text for Alice in Wonderland\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cZCXfTQGcj-W","executionInfo":{"status":"ok","timestamp":1620057394251,"user_tz":-180,"elapsed":4715201,"user":{"displayName":"יוסי גבריאל","photoUrl":"","userId":"07461216696072158750"}},"outputId":"862c022a-47bf-498d-d0d1-95b3f9a45365"},"source":["\t\n","import numpy\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.layers import Dropout\n","from keras.layers import LSTM\n","from keras.callbacks import ModelCheckpoint\n","from keras.utils import np_utils\n","# load ascii text and covert to lowercase\n","raw_text = open(learning_file_path, 'r', encoding='utf-8').read()\n","#raw_text = text.lower()\n","# create mapping of unique chars to integers\n","chars = sorted(list(set(raw_text)))\n","char_to_int = dict((c, i) for i, c in enumerate(chars))\n","# summarize the loaded data\n","n_chars = len(raw_text)\n","n_vocab = len(chars)\n","print (\"Total Characters: \", n_chars)\n","print (\"Total Vocab: \", n_vocab)\n","# prepare the dataset of input to output pairs encoded as integers\n","seq_length = 100\n","dataX = []\n","dataY = []\n","for i in range(0, n_chars - seq_length, 1):\n","    seq_in = raw_text[i:i + seq_length]\n","    seq_out = raw_text[i + seq_length]\n","    dataX.append([char_to_int[char] for char in seq_in])\n","    dataY.append(char_to_int[seq_out])\n","n_patterns = len(dataX)\n","print (\"Total Patterns: \", n_patterns)\n","# reshape X to be [samples, time steps, features]\n","X = numpy.reshape(dataX, (n_patterns, seq_length, 1))\n","# normalize\n","X = X / float(n_vocab)\n","# one hot encode the output variable\n","y = np_utils.to_categorical(dataY)\n","# define the LSTM model\n","model = Sequential()\n","model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2]), return_sequences=True))\n","model.add(Dropout(0.2))\n","model.add(LSTM(256))\n","model.add(Dropout(0.2))\n","model.add(Dense(y.shape[1], activation='softmax'))\n","model.compile(loss='categorical_crossentropy', optimizer='adam')\n","# define the checkpoint\n","filepath=f\"{saving_weights_path}/weights-improvement-{epoch:02d}-{loss:.4f}-bigger.hdf5\"\n","checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n","callbacks_list = [checkpoint]\n","# fit the model\n","model.fit(X, y, epochs=50, batch_size=64, callbacks=callbacks_list)"],"execution_count":11,"outputs":[{"output_type":"stream","text":["Total Characters:  5210\n","Total Vocab:  55\n","Total Patterns:  5110\n","Epoch 1/50\n","80/80 [==============================] - 99s 1s/step - loss: 3.4079\n","\n","Epoch 00001: loss improved from inf to 3.29542, saving model to /content/drive/MyDrive/semes_2/semester_2/advenced_mechine_learning/ex3/weights/weights-improvement-01-3.2954-bigger.hdf5\n","Epoch 2/50\n","80/80 [==============================] - 96s 1s/step - loss: 3.2416\n","\n","Epoch 00002: loss improved from 3.29542 to 3.23941, saving model to /content/drive/MyDrive/semes_2/semester_2/advenced_mechine_learning/ex3/weights/weights-improvement-02-3.2394-bigger.hdf5\n","Epoch 3/50\n","80/80 [==============================] - 95s 1s/step - loss: 3.2171\n","\n","Epoch 00003: loss improved from 3.23941 to 3.20493, saving model to /content/drive/MyDrive/semes_2/semester_2/advenced_mechine_learning/ex3/weights/weights-improvement-03-3.2049-bigger.hdf5\n","Epoch 4/50\n","80/80 [==============================] - 94s 1s/step - loss: 3.1631\n","\n","Epoch 00004: loss improved from 3.20493 to 3.16245, saving model to /content/drive/MyDrive/semes_2/semester_2/advenced_mechine_learning/ex3/weights/weights-improvement-04-3.1625-bigger.hdf5\n","Epoch 5/50\n","80/80 [==============================] - 94s 1s/step - loss: 3.1378\n","\n","Epoch 00005: loss improved from 3.16245 to 3.13385, saving model to /content/drive/MyDrive/semes_2/semester_2/advenced_mechine_learning/ex3/weights/weights-improvement-05-3.1338-bigger.hdf5\n","Epoch 6/50\n","80/80 [==============================] - 94s 1s/step - loss: 3.1148\n","\n","Epoch 00006: loss improved from 3.13385 to 3.12599, saving model to /content/drive/MyDrive/semes_2/semester_2/advenced_mechine_learning/ex3/weights/weights-improvement-06-3.1260-bigger.hdf5\n","Epoch 7/50\n","80/80 [==============================] - 93s 1s/step - loss: 3.1394\n","\n","Epoch 00007: loss improved from 3.12599 to 3.11127, saving model to /content/drive/MyDrive/semes_2/semester_2/advenced_mechine_learning/ex3/weights/weights-improvement-07-3.1113-bigger.hdf5\n","Epoch 8/50\n","80/80 [==============================] - 93s 1s/step - loss: 3.0941\n","\n","Epoch 00008: loss improved from 3.11127 to 3.09938, saving model to /content/drive/MyDrive/semes_2/semester_2/advenced_mechine_learning/ex3/weights/weights-improvement-08-3.0994-bigger.hdf5\n","Epoch 9/50\n","80/80 [==============================] - 94s 1s/step - loss: 3.1056\n","\n","Epoch 00009: loss improved from 3.09938 to 3.09768, saving model to /content/drive/MyDrive/semes_2/semester_2/advenced_mechine_learning/ex3/weights/weights-improvement-09-3.0977-bigger.hdf5\n","Epoch 10/50\n","80/80 [==============================] - 93s 1s/step - loss: 3.0734\n","\n","Epoch 00010: loss improved from 3.09768 to 3.06441, saving model to /content/drive/MyDrive/semes_2/semester_2/advenced_mechine_learning/ex3/weights/weights-improvement-10-3.0644-bigger.hdf5\n","Epoch 11/50\n","80/80 [==============================] - 93s 1s/step - loss: 3.0343\n","\n","Epoch 00011: loss improved from 3.06441 to 3.03370, saving model to /content/drive/MyDrive/semes_2/semester_2/advenced_mechine_learning/ex3/weights/weights-improvement-11-3.0337-bigger.hdf5\n","Epoch 12/50\n","80/80 [==============================] - 93s 1s/step - loss: 3.0226\n","\n","Epoch 00012: loss improved from 3.03370 to 2.99315, saving model to /content/drive/MyDrive/semes_2/semester_2/advenced_mechine_learning/ex3/weights/weights-improvement-12-2.9931-bigger.hdf5\n","Epoch 13/50\n","80/80 [==============================] - 94s 1s/step - loss: 2.9707\n","\n","Epoch 00013: loss improved from 2.99315 to 2.95538, saving model to /content/drive/MyDrive/semes_2/semester_2/advenced_mechine_learning/ex3/weights/weights-improvement-13-2.9554-bigger.hdf5\n","Epoch 14/50\n","80/80 [==============================] - 93s 1s/step - loss: 2.9235\n","\n","Epoch 00014: loss improved from 2.95538 to 2.90877, saving model to /content/drive/MyDrive/semes_2/semester_2/advenced_mechine_learning/ex3/weights/weights-improvement-14-2.9088-bigger.hdf5\n","Epoch 15/50\n","80/80 [==============================] - 95s 1s/step - loss: 2.8522\n","\n","Epoch 00015: loss improved from 2.90877 to 2.85590, saving model to /content/drive/MyDrive/semes_2/semester_2/advenced_mechine_learning/ex3/weights/weights-improvement-15-2.8559-bigger.hdf5\n","Epoch 16/50\n","80/80 [==============================] - 94s 1s/step - loss: 2.7955\n","\n","Epoch 00016: loss improved from 2.85590 to 2.82273, saving model to /content/drive/MyDrive/semes_2/semester_2/advenced_mechine_learning/ex3/weights/weights-improvement-16-2.8227-bigger.hdf5\n","Epoch 17/50\n","80/80 [==============================] - 94s 1s/step - loss: 2.7596\n","\n","Epoch 00017: loss improved from 2.82273 to 2.77295, saving model to /content/drive/MyDrive/semes_2/semester_2/advenced_mechine_learning/ex3/weights/weights-improvement-17-2.7729-bigger.hdf5\n","Epoch 18/50\n","80/80 [==============================] - 97s 1s/step - loss: 2.7117\n","\n","Epoch 00018: loss improved from 2.77295 to 2.73978, saving model to /content/drive/MyDrive/semes_2/semester_2/advenced_mechine_learning/ex3/weights/weights-improvement-18-2.7398-bigger.hdf5\n","Epoch 19/50\n","80/80 [==============================] - 95s 1s/step - loss: 2.6931\n","\n","Epoch 00019: loss improved from 2.73978 to 2.69008, saving model to /content/drive/MyDrive/semes_2/semester_2/advenced_mechine_learning/ex3/weights/weights-improvement-19-2.6901-bigger.hdf5\n","Epoch 20/50\n","80/80 [==============================] - 94s 1s/step - loss: 2.6226\n","\n","Epoch 00020: loss improved from 2.69008 to 2.64789, saving model to /content/drive/MyDrive/semes_2/semester_2/advenced_mechine_learning/ex3/weights/weights-improvement-20-2.6479-bigger.hdf5\n","Epoch 21/50\n","80/80 [==============================] - 94s 1s/step - loss: 2.8063\n","\n","Epoch 00021: loss did not improve from 2.64789\n","Epoch 22/50\n","80/80 [==============================] - 95s 1s/step - loss: 2.6352\n","\n","Epoch 00022: loss improved from 2.64789 to 2.61938, saving model to /content/drive/MyDrive/semes_2/semester_2/advenced_mechine_learning/ex3/weights/weights-improvement-22-2.6194-bigger.hdf5\n","Epoch 23/50\n","80/80 [==============================] - 95s 1s/step - loss: 2.5691\n","\n","Epoch 00023: loss improved from 2.61938 to 2.55815, saving model to /content/drive/MyDrive/semes_2/semester_2/advenced_mechine_learning/ex3/weights/weights-improvement-23-2.5582-bigger.hdf5\n","Epoch 24/50\n","80/80 [==============================] - 94s 1s/step - loss: 2.5144\n","\n","Epoch 00024: loss improved from 2.55815 to 2.51683, saving model to /content/drive/MyDrive/semes_2/semester_2/advenced_mechine_learning/ex3/weights/weights-improvement-24-2.5168-bigger.hdf5\n","Epoch 25/50\n","80/80 [==============================] - 94s 1s/step - loss: 2.4661\n","\n","Epoch 00025: loss improved from 2.51683 to 2.47539, saving model to /content/drive/MyDrive/semes_2/semester_2/advenced_mechine_learning/ex3/weights/weights-improvement-25-2.4754-bigger.hdf5\n","Epoch 26/50\n","80/80 [==============================] - 95s 1s/step - loss: 2.4550\n","\n","Epoch 00026: loss improved from 2.47539 to 2.43080, saving model to /content/drive/MyDrive/semes_2/semester_2/advenced_mechine_learning/ex3/weights/weights-improvement-26-2.4308-bigger.hdf5\n","Epoch 27/50\n","80/80 [==============================] - 95s 1s/step - loss: 2.3917\n","\n","Epoch 00027: loss improved from 2.43080 to 2.39007, saving model to /content/drive/MyDrive/semes_2/semester_2/advenced_mechine_learning/ex3/weights/weights-improvement-27-2.3901-bigger.hdf5\n","Epoch 28/50\n","80/80 [==============================] - 94s 1s/step - loss: 2.3734\n","\n","Epoch 00028: loss improved from 2.39007 to 2.35290, saving model to /content/drive/MyDrive/semes_2/semester_2/advenced_mechine_learning/ex3/weights/weights-improvement-28-2.3529-bigger.hdf5\n","Epoch 29/50\n","80/80 [==============================] - 95s 1s/step - loss: 2.2774\n","\n","Epoch 00029: loss improved from 2.35290 to 2.31016, saving model to /content/drive/MyDrive/semes_2/semester_2/advenced_mechine_learning/ex3/weights/weights-improvement-29-2.3102-bigger.hdf5\n","Epoch 30/50\n","80/80 [==============================] - 96s 1s/step - loss: 2.2648\n","\n","Epoch 00030: loss improved from 2.31016 to 2.25463, saving model to /content/drive/MyDrive/semes_2/semester_2/advenced_mechine_learning/ex3/weights/weights-improvement-30-2.2546-bigger.hdf5\n","Epoch 31/50\n","80/80 [==============================] - 94s 1s/step - loss: 2.2229\n","\n","Epoch 00031: loss improved from 2.25463 to 2.21334, saving model to /content/drive/MyDrive/semes_2/semester_2/advenced_mechine_learning/ex3/weights/weights-improvement-31-2.2133-bigger.hdf5\n","Epoch 32/50\n","80/80 [==============================] - 93s 1s/step - loss: 2.1613\n","\n","Epoch 00032: loss improved from 2.21334 to 2.16582, saving model to /content/drive/MyDrive/semes_2/semester_2/advenced_mechine_learning/ex3/weights/weights-improvement-32-2.1658-bigger.hdf5\n","Epoch 33/50\n","80/80 [==============================] - 94s 1s/step - loss: 2.1032\n","\n","Epoch 00033: loss improved from 2.16582 to 2.10561, saving model to /content/drive/MyDrive/semes_2/semester_2/advenced_mechine_learning/ex3/weights/weights-improvement-33-2.1056-bigger.hdf5\n","Epoch 34/50\n","80/80 [==============================] - 94s 1s/step - loss: 2.0327\n","\n","Epoch 00034: loss improved from 2.10561 to 2.04697, saving model to /content/drive/MyDrive/semes_2/semester_2/advenced_mechine_learning/ex3/weights/weights-improvement-34-2.0470-bigger.hdf5\n","Epoch 35/50\n","80/80 [==============================] - 93s 1s/step - loss: 1.9715\n","\n","Epoch 00035: loss improved from 2.04697 to 2.01021, saving model to /content/drive/MyDrive/semes_2/semester_2/advenced_mechine_learning/ex3/weights/weights-improvement-35-2.0102-bigger.hdf5\n","Epoch 36/50\n","80/80 [==============================] - 93s 1s/step - loss: 1.8912\n","\n","Epoch 00036: loss improved from 2.01021 to 1.93052, saving model to /content/drive/MyDrive/semes_2/semester_2/advenced_mechine_learning/ex3/weights/weights-improvement-36-1.9305-bigger.hdf5\n","Epoch 37/50\n","80/80 [==============================] - 93s 1s/step - loss: 1.8320\n","\n","Epoch 00037: loss improved from 1.93052 to 1.86961, saving model to /content/drive/MyDrive/semes_2/semester_2/advenced_mechine_learning/ex3/weights/weights-improvement-37-1.8696-bigger.hdf5\n","Epoch 38/50\n","80/80 [==============================] - 92s 1s/step - loss: 1.7775\n","\n","Epoch 00038: loss improved from 1.86961 to 1.80051, saving model to /content/drive/MyDrive/semes_2/semester_2/advenced_mechine_learning/ex3/weights/weights-improvement-38-1.8005-bigger.hdf5\n","Epoch 39/50\n","80/80 [==============================] - 92s 1s/step - loss: 1.7305\n","\n","Epoch 00039: loss improved from 1.80051 to 1.74257, saving model to /content/drive/MyDrive/semes_2/semester_2/advenced_mechine_learning/ex3/weights/weights-improvement-39-1.7426-bigger.hdf5\n","Epoch 40/50\n","80/80 [==============================] - 93s 1s/step - loss: 1.6549\n","\n","Epoch 00040: loss improved from 1.74257 to 1.67832, saving model to /content/drive/MyDrive/semes_2/semester_2/advenced_mechine_learning/ex3/weights/weights-improvement-40-1.6783-bigger.hdf5\n","Epoch 41/50\n","80/80 [==============================] - 92s 1s/step - loss: 1.5955\n","\n","Epoch 00041: loss improved from 1.67832 to 1.61377, saving model to /content/drive/MyDrive/semes_2/semester_2/advenced_mechine_learning/ex3/weights/weights-improvement-41-1.6138-bigger.hdf5\n","Epoch 42/50\n","80/80 [==============================] - 91s 1s/step - loss: 1.5101\n","\n","Epoch 00042: loss improved from 1.61377 to 1.54808, saving model to /content/drive/MyDrive/semes_2/semester_2/advenced_mechine_learning/ex3/weights/weights-improvement-42-1.5481-bigger.hdf5\n","Epoch 43/50\n","80/80 [==============================] - 93s 1s/step - loss: 1.4674\n","\n","Epoch 00043: loss improved from 1.54808 to 1.47333, saving model to /content/drive/MyDrive/semes_2/semester_2/advenced_mechine_learning/ex3/weights/weights-improvement-43-1.4733-bigger.hdf5\n","Epoch 44/50\n","80/80 [==============================] - 93s 1s/step - loss: 1.4113\n","\n","Epoch 00044: loss improved from 1.47333 to 1.41220, saving model to /content/drive/MyDrive/semes_2/semester_2/advenced_mechine_learning/ex3/weights/weights-improvement-44-1.4122-bigger.hdf5\n","Epoch 45/50\n","80/80 [==============================] - 95s 1s/step - loss: 1.3017\n","\n","Epoch 00045: loss improved from 1.41220 to 1.34785, saving model to /content/drive/MyDrive/semes_2/semester_2/advenced_mechine_learning/ex3/weights/weights-improvement-45-1.3479-bigger.hdf5\n","Epoch 46/50\n","80/80 [==============================] - 96s 1s/step - loss: 1.2369\n","\n","Epoch 00046: loss improved from 1.34785 to 1.27362, saving model to /content/drive/MyDrive/semes_2/semester_2/advenced_mechine_learning/ex3/weights/weights-improvement-46-1.2736-bigger.hdf5\n","Epoch 47/50\n","80/80 [==============================] - 96s 1s/step - loss: 1.2062\n","\n","Epoch 00047: loss improved from 1.27362 to 1.20880, saving model to /content/drive/MyDrive/semes_2/semester_2/advenced_mechine_learning/ex3/weights/weights-improvement-47-1.2088-bigger.hdf5\n","Epoch 48/50\n","80/80 [==============================] - 95s 1s/step - loss: 1.1323\n","\n","Epoch 00048: loss improved from 1.20880 to 1.14804, saving model to /content/drive/MyDrive/semes_2/semester_2/advenced_mechine_learning/ex3/weights/weights-improvement-48-1.1480-bigger.hdf5\n","Epoch 49/50\n","80/80 [==============================] - 94s 1s/step - loss: 1.0698\n","\n","Epoch 00049: loss improved from 1.14804 to 1.09404, saving model to /content/drive/MyDrive/semes_2/semester_2/advenced_mechine_learning/ex3/weights/weights-improvement-49-1.0940-bigger.hdf5\n","Epoch 50/50\n","80/80 [==============================] - 96s 1s/step - loss: 1.0009\n","\n","Epoch 00050: loss improved from 1.09404 to 1.02399, saving model to /content/drive/MyDrive/semes_2/semester_2/advenced_mechine_learning/ex3/weights/weights-improvement-50-1.0240-bigger.hdf5\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f1a47116a10>"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"markdown","metadata":{"id":"fG-svCm2bmcO"},"source":["# Load Larger LSTM network and generate text"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DOIUX0LygwHp","executionInfo":{"status":"ok","timestamp":1620063577741,"user_tz":-180,"elapsed":73767,"user":{"displayName":"יוסי גבריאל","photoUrl":"","userId":"07461216696072158750"}},"outputId":"cbd11e8c-5d4c-4bfb-e098-cf0955fa44ab"},"source":["\n","import sys\n","import numpy\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.layers import Dropout\n","from keras.layers import LSTM\n","from keras.callbacks import ModelCheckpoint\n","from keras.utils import np_utils\n","# load ascii text and covert to lowercase\n","filename = \"wonderland.txt\"\n","#raw_text = open(filename, 'r', encoding='utf-8').read()\n","txt = 'Methods for coordinating data-gathering with standardized nomenclature, Methods for coordinating data-gathering with standardized nomenclature'\n","txt = text = ' and the Athena Elevated Temperature Detection System (Athena Security, Austin, TX). Exergen reports their instruments to be accurate within 0.2°C and 0.1°C, respectively.3,4 The Athena telethermographic system uses artificial intelligence to detect human faces by measuring the temperature of multiple points on the face relative to a blackbody temperature reference source.5 According to Athena Security, the system is accurate within 0.3°C.5 Systems were purchased from Athena Security. Accepting manufacturer specifications, detecting 0.2°C difference between devices (assuming standard deviation of ±0.3°C) required 26 measurements from each device. One subject was measured 104 times with 4 different TAT-2000s (26 measurements per device) and 104 times with 4 different TAT-5000s (26 measurements per device) by a single operator, and 13 times with the Athena system at a single location within 90 minutes to minimize subject and environmental temperature variation. We repeated measurements with the same subject and thermometer operator at a second location with 3 additional TAT-5000s, 1 TAT-5000 used previously (104 measurements, 26 per device) and a second thermal camera (13 measurements). We simulated fever using air-activated hand warmers (HotHands, Kobayashi Americas, Dalton, GA) held to the forehead. Descriptive statistical analyses were performed with Stata version 15 SE software (StataCorp, College Station, TX). Summaries were reported as means with 95% confidence intervals and differences were tested by 1-way ANOVA. A 2-sided P < .05 was considered statistically significant. During the first session, the TAT-2000s measured higher temperatures [mean, 98.3°F (95% CI, 98.2–98.3) or 36.8°C (95% CI, 36.8–36.8)] than the TAT-5000s [mean, 97.8 °F (95% CI, 97.8–97.9) or 36.6°C (95% CI, 36.5–36.6)] or the Athena system [mean, 97.9°F (95% CI, 97.8–98.0) or 36.6°C (95% CI, 36.5–36.7)] (P < .05). There was no significant difference between the TAT-5000s and the Athena system [mean difference, −0.07°F (95% CI, −0.23 to 0.09) or −0.04°C (95% CI, −0.13 to 0.05)], but the TAT-2000s measured temperatures significantly higher than the Athena [mean difference, 0.40°F (95% CI, 0.24–0.56) or 0.22°C (95% CI, 0.13–0.31)]. During the second testing session, the TAT-5000s measured 0.34°F (95% CI, 0.20–0.48) or 0.19°C (95% CI, 0.11–0.26) [mean, 98.1°F (95% CI, 98.1–98.2) or 36.7°C (95% CI, 36.7–36.8)] higher than the Athena system [mean, 97.8°F (95% CI, 97.7–97.9) or 36.6°C (95% CI, 36.5–36.6)] (P < .05). HotHands warmers reached up to 46.1°C (115°F) 15–30 minutes after activation and were held at the forehead. A “symptomatic” individual in single-file line 6 feet (2 m) between “normal” individuals passing the camera at a rate of 1 individual per second, was detected in 8 of 8 attempts. Additionally, when the forehead was warmed and the warmer then removed, the Athena system was able to detect temperatures of >99°F or 37.2°C (Fig. 1) in 5 of 5 attempts. \\n\\n Screeners using TAT-5000s took a median of 16.5 seconds from the start of taking the temperature through cleaning the device until the thermometer was ready again. The Athena system has no effective delay from person to person passing in a single-file line. The COVID-19 pandemic has led to the implementation of temperature screening in a wide variety of facilities. Although temperature screening has been used in public settings during previous infectious diseases outbreaks,6–8 the usefulness of temperature screening to detect potential infections has been questioned.6,7 However, temperature screening may discourage symptomatic individuals from entering public places and may increase comfort for healthy people.8\\n Our study using noninvasive devices was not designed to test the accuracy of devices, though temporal scanners are widely considered reliable enough for professional use.9,10 In our use, temperatures measured by telethermographic systems were similar to those obtained by temporal scanners, suggesting similar performance. Cost is the biggest barrier to implementation for telethermographic systems. For our investment recovery analysis, we considered turnaround time difference between temporal scanners and a thermal camera for each screened individual at a high-entry location with large groups arriving in a short period, desired throughput rate of 1 person per second, maintaining 6-feet (2-m) social distancing and single-file lines for individual symptom screening. We estimated needing 6 temporal scanner operators for every 1 thermal camera operator. With our organization’s direct labor rates and overhead costs, investment recovery was estimated to occur in months, leading to adoption of 4 telethermographic systems at our 2 highest-entry locations. We reduced screening staff from 24 to 4 individuals, and there are now no waiting lines at these locations. In conclusion, our experience demonstrates that a telethermographic system improves screening throughput and reports temperatures similar to those recorded by temporal scanners, with acceptable investment recovery time.'\n","raw_text = txt.lower()\n","print(raw_text)\n","# create mapping of unique chars to integers, and a reverse mapping\n","chars = sorted(list(set(raw_text)))\n","char_to_int = dict((c, i) for i, c in enumerate(chars))\n","int_to_char = dict((i, c) for i, c in enumerate(chars))\n","# summarize the loaded data\n","n_chars = len(raw_text)\n","n_vocab = len(chars)\n","print (\"Total Characters: \", n_chars)\n","print (\"Total Vocab: \", n_vocab)\n","# prepare the dataset of input to output pairs encoded as integers\n","seq_length = 100\n","dataX = []\n","dataY = []\n","for i in range(0, n_chars - seq_length, 1):\n","\tseq_in = raw_text[i:i + seq_length]\n","\tseq_out = raw_text[i + seq_length]\n","\tdataX.append([char_to_int[char] for char in seq_in])\n","\tdataY.append(char_to_int[seq_out])\n","n_patterns = len(dataX)\n","print (\"Total Patterns: \", n_patterns)\n","# reshape X to be [samples, time steps, features]\n","X = numpy.reshape(dataX, (n_patterns, seq_length, 1))\n","# normalize\n","X = X / float(n_vocab)\n","# one hot encode the output variable\n","print(dataY)\n","y = np_utils.to_categorical(dataY)\n","\n","# define the LSTM model\n","model = Sequential()\n","model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2]), return_sequences=True))\n","model.add(Dropout(0.2))\n","model.add(LSTM(256))\n","model.add(Dropout(0.2))\n","model.add(Dense(y.shape[1], activation='softmax'))\n","\n","# load the network weights\n","model.load_weights(weights_file_path)\n","\n","model.compile(loss='categorical_crossentropy', optimizer='adam')\n","# pick a random seed\n","start = numpy.random.randint(0, len(dataX)-1)\n","pattern = dataX[start]\n","print (\"Seed:\")\n","print (\"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"\\\"\")\n","# generate characters\n","for i in range(1000):\n","\tx = numpy.reshape(pattern, (1, len(pattern), 1))\n","\tx = x / float(n_vocab)\n","\tprediction = model.predict(x, verbose=0)\n","\tindex = numpy.argmax(prediction)\n","\tresult = int_to_char[index]\n","\tseq_in = [int_to_char[value] for value in pattern]\n","\tsys.stdout.write(result)\n","\tpattern.append(index)\n","\tpattern = pattern[1:len(pattern)]\n","print (\"\\nDone.\")"],"execution_count":38,"outputs":[{"output_type":"stream","text":[" and the athena elevated temperature detection system (athena security, austin, tx). exergen reports their instruments to be accurate within 0.2°c and 0.1°c, respectively.3,4 the athena telethermographic system uses artificial intelligence to detect human faces by measuring the temperature of multiple points on the face relative to a blackbody temperature reference source.5 according to athena security, the system is accurate within 0.3°c.5 systems were purchased from athena security. accepting manufacturer specifications, detecting 0.2°c difference between devices (assuming standard deviation of ±0.3°c) required 26 measurements from each device. one subject was measured 104 times with 4 different tat-2000s (26 measurements per device) and 104 times with 4 different tat-5000s (26 measurements per device) by a single operator, and 13 times with the athena system at a single location within 90 minutes to minimize subject and environmental temperature variation. we repeated measurements with the same subject and thermometer operator at a second location with 3 additional tat-5000s, 1 tat-5000 used previously (104 measurements, 26 per device) and a second thermal camera (13 measurements). we simulated fever using air-activated hand warmers (hothands, kobayashi americas, dalton, ga) held to the forehead. descriptive statistical analyses were performed with stata version 15 se software (statacorp, college station, tx). summaries were reported as means with 95% confidence intervals and differences were tested by 1-way anova. a 2-sided p < .05 was considered statistically significant. during the first session, the tat-2000s measured higher temperatures [mean, 98.3°f (95% ci, 98.2–98.3) or 36.8°c (95% ci, 36.8–36.8)] than the tat-5000s [mean, 97.8 °f (95% ci, 97.8–97.9) or 36.6°c (95% ci, 36.5–36.6)] or the athena system [mean, 97.9°f (95% ci, 97.8–98.0) or 36.6°c (95% ci, 36.5–36.7)] (p < .05). there was no significant difference between the tat-5000s and the athena system [mean difference, −0.07°f (95% ci, −0.23 to 0.09) or −0.04°c (95% ci, −0.13 to 0.05)], but the tat-2000s measured temperatures significantly higher than the athena [mean difference, 0.40°f (95% ci, 0.24–0.56) or 0.22°c (95% ci, 0.13–0.31)]. during the second testing session, the tat-5000s measured 0.34°f (95% ci, 0.20–0.48) or 0.19°c (95% ci, 0.11–0.26) [mean, 98.1°f (95% ci, 98.1–98.2) or 36.7°c (95% ci, 36.7–36.8)] higher than the athena system [mean, 97.8°f (95% ci, 97.7–97.9) or 36.6°c (95% ci, 36.5–36.6)] (p < .05). hothands warmers reached up to 46.1°c (115°f) 15–30 minutes after activation and were held at the forehead. a “symptomatic” individual in single-file line 6 feet (2 m) between “normal” individuals passing the camera at a rate of 1 individual per second, was detected in 8 of 8 attempts. additionally, when the forehead was warmed and the warmer then removed, the athena system was able to detect temperatures of >99°f or 37.2°c (fig. 1) in 5 of 5 attempts. \n","\n"," screeners using tat-5000s took a median of 16.5 seconds from the start of taking the temperature through cleaning the device until the thermometer was ready again. the athena system has no effective delay from person to person passing in a single-file line. the covid-19 pandemic has led to the implementation of temperature screening in a wide variety of facilities. although temperature screening has been used in public settings during previous infectious diseases outbreaks,6–8 the usefulness of temperature screening to detect potential infections has been questioned.6,7 however, temperature screening may discourage symptomatic individuals from entering public places and may increase comfort for healthy people.8\n"," our study using noninvasive devices was not designed to test the accuracy of devices, though temporal scanners are widely considered reliable enough for professional use.9,10 in our use, temperatures measured by telethermographic systems were similar to those obtained by temporal scanners, suggesting similar performance. cost is the biggest barrier to implementation for telethermographic systems. for our investment recovery analysis, we considered turnaround time difference between temporal scanners and a thermal camera for each screened individual at a high-entry location with large groups arriving in a short period, desired throughput rate of 1 person per second, maintaining 6-feet (2-m) social distancing and single-file lines for individual symptom screening. we estimated needing 6 temporal scanner operators for every 1 thermal camera operator. with our organization’s direct labor rates and overhead costs, investment recovery was estimated to occur in months, leading to adoption of 4 telethermographic systems at our 2 highest-entry locations. we reduced screening staff from 24 to 4 individuals, and there are now no waiting lines at these locations. in conclusion, our experience demonstrates that a telethermographic system improves screening throughput and reports temperatures similar to those recorded by temporal scanners, with acceptable investment recovery time.\n","Total Characters:  5098\n","Total Vocab:  55\n","Total Patterns:  4998\n","[1, 41, 29, 26, 30, 39, 1, 30, 35, 40, 41, 39, 42, 34, 26, 35, 41, 40, 1, 41, 36, 1, 23, 26, 1, 22, 24, 24, 42, 39, 22, 41, 26, 1, 44, 30, 41, 29, 30, 35, 1, 8, 7, 10, 48, 24, 1, 22, 35, 25, 1, 8, 7, 9, 48, 24, 5, 1, 39, 26, 40, 37, 26, 24, 41, 30, 43, 26, 33, 46, 7, 11, 5, 12, 1, 41, 29, 26, 1, 22, 41, 29, 26, 35, 22, 1, 41, 26, 33, 26, 41, 29, 26, 39, 34, 36, 28, 39, 22, 37, 29, 30, 24, 1, 40, 46, 40, 41, 26, 34, 1, 42, 40, 26, 40, 1, 22, 39, 41, 30, 27, 30, 24, 30, 22, 33, 1, 30, 35, 41, 26, 33, 33, 30, 28, 26, 35, 24, 26, 1, 41, 36, 1, 25, 26, 41, 26, 24, 41, 1, 29, 42, 34, 22, 35, 1, 27, 22, 24, 26, 40, 1, 23, 46, 1, 34, 26, 22, 40, 42, 39, 30, 35, 28, 1, 41, 29, 26, 1, 41, 26, 34, 37, 26, 39, 22, 41, 42, 39, 26, 1, 36, 27, 1, 34, 42, 33, 41, 30, 37, 33, 26, 1, 37, 36, 30, 35, 41, 40, 1, 36, 35, 1, 41, 29, 26, 1, 27, 22, 24, 26, 1, 39, 26, 33, 22, 41, 30, 43, 26, 1, 41, 36, 1, 22, 1, 23, 33, 22, 24, 32, 23, 36, 25, 46, 1, 41, 26, 34, 37, 26, 39, 22, 41, 42, 39, 26, 1, 39, 26, 27, 26, 39, 26, 35, 24, 26, 1, 40, 36, 42, 39, 24, 26, 7, 13, 1, 22, 24, 24, 36, 39, 25, 30, 35, 28, 1, 41, 36, 1, 22, 41, 29, 26, 35, 22, 1, 40, 26, 24, 42, 39, 30, 41, 46, 5, 1, 41, 29, 26, 1, 40, 46, 40, 41, 26, 34, 1, 30, 40, 1, 22, 24, 24, 42, 39, 22, 41, 26, 1, 44, 30, 41, 29, 30, 35, 1, 8, 7, 11, 48, 24, 7, 13, 1, 40, 46, 40, 41, 26, 34, 40, 1, 44, 26, 39, 26, 1, 37, 42, 39, 24, 29, 22, 40, 26, 25, 1, 27, 39, 36, 34, 1, 22, 41, 29, 26, 35, 22, 1, 40, 26, 24, 42, 39, 30, 41, 46, 7, 1, 22, 24, 24, 26, 37, 41, 30, 35, 28, 1, 34, 22, 35, 42, 27, 22, 24, 41, 42, 39, 26, 39, 1, 40, 37, 26, 24, 30, 27, 30, 24, 22, 41, 30, 36, 35, 40, 5, 1, 25, 26, 41, 26, 24, 41, 30, 35, 28, 1, 8, 7, 10, 48, 24, 1, 25, 30, 27, 27, 26, 39, 26, 35, 24, 26, 1, 23, 26, 41, 44, 26, 26, 35, 1, 25, 26, 43, 30, 24, 26, 40, 1, 3, 22, 40, 40, 42, 34, 30, 35, 28, 1, 40, 41, 22, 35, 25, 22, 39, 25, 1, 25, 26, 43, 30, 22, 41, 30, 36, 35, 1, 36, 27, 1, 49, 8, 7, 11, 48, 24, 4, 1, 39, 26, 38, 42, 30, 39, 26, 25, 1, 10, 14, 1, 34, 26, 22, 40, 42, 39, 26, 34, 26, 35, 41, 40, 1, 27, 39, 36, 34, 1, 26, 22, 24, 29, 1, 25, 26, 43, 30, 24, 26, 7, 1, 36, 35, 26, 1, 40, 42, 23, 31, 26, 24, 41, 1, 44, 22, 40, 1, 34, 26, 22, 40, 42, 39, 26, 25, 1, 9, 8, 12, 1, 41, 30, 34, 26, 40, 1, 44, 30, 41, 29, 1, 12, 1, 25, 30, 27, 27, 26, 39, 26, 35, 41, 1, 41, 22, 41, 6, 10, 8, 8, 8, 40, 1, 3, 10, 14, 1, 34, 26, 22, 40, 42, 39, 26, 34, 26, 35, 41, 40, 1, 37, 26, 39, 1, 25, 26, 43, 30, 24, 26, 4, 1, 22, 35, 25, 1, 9, 8, 12, 1, 41, 30, 34, 26, 40, 1, 44, 30, 41, 29, 1, 12, 1, 25, 30, 27, 27, 26, 39, 26, 35, 41, 1, 41, 22, 41, 6, 13, 8, 8, 8, 40, 1, 3, 10, 14, 1, 34, 26, 22, 40, 42, 39, 26, 34, 26, 35, 41, 40, 1, 37, 26, 39, 1, 25, 26, 43, 30, 24, 26, 4, 1, 23, 46, 1, 22, 1, 40, 30, 35, 28, 33, 26, 1, 36, 37, 26, 39, 22, 41, 36, 39, 5, 1, 22, 35, 25, 1, 9, 11, 1, 41, 30, 34, 26, 40, 1, 44, 30, 41, 29, 1, 41, 29, 26, 1, 22, 41, 29, 26, 35, 22, 1, 40, 46, 40, 41, 26, 34, 1, 22, 41, 1, 22, 1, 40, 30, 35, 28, 33, 26, 1, 33, 36, 24, 22, 41, 30, 36, 35, 1, 44, 30, 41, 29, 30, 35, 1, 17, 8, 1, 34, 30, 35, 42, 41, 26, 40, 1, 41, 36, 1, 34, 30, 35, 30, 34, 30, 47, 26, 1, 40, 42, 23, 31, 26, 24, 41, 1, 22, 35, 25, 1, 26, 35, 43, 30, 39, 36, 35, 34, 26, 35, 41, 22, 33, 1, 41, 26, 34, 37, 26, 39, 22, 41, 42, 39, 26, 1, 43, 22, 39, 30, 22, 41, 30, 36, 35, 7, 1, 44, 26, 1, 39, 26, 37, 26, 22, 41, 26, 25, 1, 34, 26, 22, 40, 42, 39, 26, 34, 26, 35, 41, 40, 1, 44, 30, 41, 29, 1, 41, 29, 26, 1, 40, 22, 34, 26, 1, 40, 42, 23, 31, 26, 24, 41, 1, 22, 35, 25, 1, 41, 29, 26, 39, 34, 36, 34, 26, 41, 26, 39, 1, 36, 37, 26, 39, 22, 41, 36, 39, 1, 22, 41, 1, 22, 1, 40, 26, 24, 36, 35, 25, 1, 33, 36, 24, 22, 41, 30, 36, 35, 1, 44, 30, 41, 29, 1, 11, 1, 22, 25, 25, 30, 41, 30, 36, 35, 22, 33, 1, 41, 22, 41, 6, 13, 8, 8, 8, 40, 5, 1, 9, 1, 41, 22, 41, 6, 13, 8, 8, 8, 1, 42, 40, 26, 25, 1, 37, 39, 26, 43, 30, 36, 42, 40, 33, 46, 1, 3, 9, 8, 12, 1, 34, 26, 22, 40, 42, 39, 26, 34, 26, 35, 41, 40, 5, 1, 10, 14, 1, 37, 26, 39, 1, 25, 26, 43, 30, 24, 26, 4, 1, 22, 35, 25, 1, 22, 1, 40, 26, 24, 36, 35, 25, 1, 41, 29, 26, 39, 34, 22, 33, 1, 24, 22, 34, 26, 39, 22, 1, 3, 9, 11, 1, 34, 26, 22, 40, 42, 39, 26, 34, 26, 35, 41, 40, 4, 7, 1, 44, 26, 1, 40, 30, 34, 42, 33, 22, 41, 26, 25, 1, 27, 26, 43, 26, 39, 1, 42, 40, 30, 35, 28, 1, 22, 30, 39, 6, 22, 24, 41, 30, 43, 22, 41, 26, 25, 1, 29, 22, 35, 25, 1, 44, 22, 39, 34, 26, 39, 40, 1, 3, 29, 36, 41, 29, 22, 35, 25, 40, 5, 1, 32, 36, 23, 22, 46, 22, 40, 29, 30, 1, 22, 34, 26, 39, 30, 24, 22, 40, 5, 1, 25, 22, 33, 41, 36, 35, 5, 1, 28, 22, 4, 1, 29, 26, 33, 25, 1, 41, 36, 1, 41, 29, 26, 1, 27, 36, 39, 26, 29, 26, 22, 25, 7, 1, 25, 26, 40, 24, 39, 30, 37, 41, 30, 43, 26, 1, 40, 41, 22, 41, 30, 40, 41, 30, 24, 22, 33, 1, 22, 35, 22, 33, 46, 40, 26, 40, 1, 44, 26, 39, 26, 1, 37, 26, 39, 27, 36, 39, 34, 26, 25, 1, 44, 30, 41, 29, 1, 40, 41, 22, 41, 22, 1, 43, 26, 39, 40, 30, 36, 35, 1, 9, 13, 1, 40, 26, 1, 40, 36, 27, 41, 44, 22, 39, 26, 1, 3, 40, 41, 22, 41, 22, 24, 36, 39, 37, 5, 1, 24, 36, 33, 33, 26, 28, 26, 1, 40, 41, 22, 41, 30, 36, 35, 5, 1, 41, 45, 4, 7, 1, 40, 42, 34, 34, 22, 39, 30, 26, 40, 1, 44, 26, 39, 26, 1, 39, 26, 37, 36, 39, 41, 26, 25, 1, 22, 40, 1, 34, 26, 22, 35, 40, 1, 44, 30, 41, 29, 1, 17, 13, 2, 1, 24, 36, 35, 27, 30, 25, 26, 35, 24, 26, 1, 30, 35, 41, 26, 39, 43, 22, 33, 40, 1, 22, 35, 25, 1, 25, 30, 27, 27, 26, 39, 26, 35, 24, 26, 40, 1, 44, 26, 39, 26, 1, 41, 26, 40, 41, 26, 25, 1, 23, 46, 1, 9, 6, 44, 22, 46, 1, 22, 35, 36, 43, 22, 7, 1, 22, 1, 10, 6, 40, 30, 25, 26, 25, 1, 37, 1, 18, 1, 7, 8, 13, 1, 44, 22, 40, 1, 24, 36, 35, 40, 30, 25, 26, 39, 26, 25, 1, 40, 41, 22, 41, 30, 40, 41, 30, 24, 22, 33, 33, 46, 1, 40, 30, 28, 35, 30, 27, 30, 24, 22, 35, 41, 7, 1, 25, 42, 39, 30, 35, 28, 1, 41, 29, 26, 1, 27, 30, 39, 40, 41, 1, 40, 26, 40, 40, 30, 36, 35, 5, 1, 41, 29, 26, 1, 41, 22, 41, 6, 10, 8, 8, 8, 40, 1, 34, 26, 22, 40, 42, 39, 26, 25, 1, 29, 30, 28, 29, 26, 39, 1, 41, 26, 34, 37, 26, 39, 22, 41, 42, 39, 26, 40, 1, 20, 34, 26, 22, 35, 5, 1, 17, 16, 7, 11, 48, 27, 1, 3, 17, 13, 2, 1, 24, 30, 5, 1, 17, 16, 7, 10, 50, 17, 16, 7, 11, 4, 1, 36, 39, 1, 11, 14, 7, 16, 48, 24, 1, 3, 17, 13, 2, 1, 24, 30, 5, 1, 11, 14, 7, 16, 50, 11, 14, 7, 16, 4, 21, 1, 41, 29, 22, 35, 1, 41, 29, 26, 1, 41, 22, 41, 6, 13, 8, 8, 8, 40, 1, 20, 34, 26, 22, 35, 5, 1, 17, 15, 7, 16, 1, 48, 27, 1, 3, 17, 13, 2, 1, 24, 30, 5, 1, 17, 15, 7, 16, 50, 17, 15, 7, 17, 4, 1, 36, 39, 1, 11, 14, 7, 14, 48, 24, 1, 3, 17, 13, 2, 1, 24, 30, 5, 1, 11, 14, 7, 13, 50, 11, 14, 7, 14, 4, 21, 1, 36, 39, 1, 41, 29, 26, 1, 22, 41, 29, 26, 35, 22, 1, 40, 46, 40, 41, 26, 34, 1, 20, 34, 26, 22, 35, 5, 1, 17, 15, 7, 17, 48, 27, 1, 3, 17, 13, 2, 1, 24, 30, 5, 1, 17, 15, 7, 16, 50, 17, 16, 7, 8, 4, 1, 36, 39, 1, 11, 14, 7, 14, 48, 24, 1, 3, 17, 13, 2, 1, 24, 30, 5, 1, 11, 14, 7, 13, 50, 11, 14, 7, 15, 4, 21, 1, 3, 37, 1, 18, 1, 7, 8, 13, 4, 7, 1, 41, 29, 26, 39, 26, 1, 44, 22, 40, 1, 35, 36, 1, 40, 30, 28, 35, 30, 27, 30, 24, 22, 35, 41, 1, 25, 30, 27, 27, 26, 39, 26, 35, 24, 26, 1, 23, 26, 41, 44, 26, 26, 35, 1, 41, 29, 26, 1, 41, 22, 41, 6, 13, 8, 8, 8, 40, 1, 22, 35, 25, 1, 41, 29, 26, 1, 22, 41, 29, 26, 35, 22, 1, 40, 46, 40, 41, 26, 34, 1, 20, 34, 26, 22, 35, 1, 25, 30, 27, 27, 26, 39, 26, 35, 24, 26, 5, 1, 54, 8, 7, 8, 15, 48, 27, 1, 3, 17, 13, 2, 1, 24, 30, 5, 1, 54, 8, 7, 10, 11, 1, 41, 36, 1, 8, 7, 8, 17, 4, 1, 36, 39, 1, 54, 8, 7, 8, 12, 48, 24, 1, 3, 17, 13, 2, 1, 24, 30, 5, 1, 54, 8, 7, 9, 11, 1, 41, 36, 1, 8, 7, 8, 13, 4, 21, 5, 1, 23, 42, 41, 1, 41, 29, 26, 1, 41, 22, 41, 6, 10, 8, 8, 8, 40, 1, 34, 26, 22, 40, 42, 39, 26, 25, 1, 41, 26, 34, 37, 26, 39, 22, 41, 42, 39, 26, 40, 1, 40, 30, 28, 35, 30, 27, 30, 24, 22, 35, 41, 33, 46, 1, 29, 30, 28, 29, 26, 39, 1, 41, 29, 22, 35, 1, 41, 29, 26, 1, 22, 41, 29, 26, 35, 22, 1, 20, 34, 26, 22, 35, 1, 25, 30, 27, 27, 26, 39, 26, 35, 24, 26, 5, 1, 8, 7, 12, 8, 48, 27, 1, 3, 17, 13, 2, 1, 24, 30, 5, 1, 8, 7, 10, 12, 50, 8, 7, 13, 14, 4, 1, 36, 39, 1, 8, 7, 10, 10, 48, 24, 1, 3, 17, 13, 2, 1, 24, 30, 5, 1, 8, 7, 9, 11, 50, 8, 7, 11, 9, 4, 21, 7, 1, 25, 42, 39, 30, 35, 28, 1, 41, 29, 26, 1, 40, 26, 24, 36, 35, 25, 1, 41, 26, 40, 41, 30, 35, 28, 1, 40, 26, 40, 40, 30, 36, 35, 5, 1, 41, 29, 26, 1, 41, 22, 41, 6, 13, 8, 8, 8, 40, 1, 34, 26, 22, 40, 42, 39, 26, 25, 1, 8, 7, 11, 12, 48, 27, 1, 3, 17, 13, 2, 1, 24, 30, 5, 1, 8, 7, 10, 8, 50, 8, 7, 12, 16, 4, 1, 36, 39, 1, 8, 7, 9, 17, 48, 24, 1, 3, 17, 13, 2, 1, 24, 30, 5, 1, 8, 7, 9, 9, 50, 8, 7, 10, 14, 4, 1, 20, 34, 26, 22, 35, 5, 1, 17, 16, 7, 9, 48, 27, 1, 3, 17, 13, 2, 1, 24, 30, 5, 1, 17, 16, 7, 9, 50, 17, 16, 7, 10, 4, 1, 36, 39, 1, 11, 14, 7, 15, 48, 24, 1, 3, 17, 13, 2, 1, 24, 30, 5, 1, 11, 14, 7, 15, 50, 11, 14, 7, 16, 4, 21, 1, 29, 30, 28, 29, 26, 39, 1, 41, 29, 22, 35, 1, 41, 29, 26, 1, 22, 41, 29, 26, 35, 22, 1, 40, 46, 40, 41, 26, 34, 1, 20, 34, 26, 22, 35, 5, 1, 17, 15, 7, 16, 48, 27, 1, 3, 17, 13, 2, 1, 24, 30, 5, 1, 17, 15, 7, 15, 50, 17, 15, 7, 17, 4, 1, 36, 39, 1, 11, 14, 7, 14, 48, 24, 1, 3, 17, 13, 2, 1, 24, 30, 5, 1, 11, 14, 7, 13, 50, 11, 14, 7, 14, 4, 21, 1, 3, 37, 1, 18, 1, 7, 8, 13, 4, 7, 1, 29, 36, 41, 29, 22, 35, 25, 40, 1, 44, 22, 39, 34, 26, 39, 40, 1, 39, 26, 22, 24, 29, 26, 25, 1, 42, 37, 1, 41, 36, 1, 12, 14, 7, 9, 48, 24, 1, 3, 9, 9, 13, 48, 27, 4, 1, 9, 13, 50, 11, 8, 1, 34, 30, 35, 42, 41, 26, 40, 1, 22, 27, 41, 26, 39, 1, 22, 24, 41, 30, 43, 22, 41, 30, 36, 35, 1, 22, 35, 25, 1, 44, 26, 39, 26, 1, 29, 26, 33, 25, 1, 22, 41, 1, 41, 29, 26, 1, 27, 36, 39, 26, 29, 26, 22, 25, 7, 1, 22, 1, 52, 40, 46, 34, 37, 41, 36, 34, 22, 41, 30, 24, 53, 1, 30, 35, 25, 30, 43, 30, 25, 42, 22, 33, 1, 30, 35, 1, 40, 30, 35, 28, 33, 26, 6, 27, 30, 33, 26, 1, 33, 30, 35, 26, 1, 14, 1, 27, 26, 26, 41, 1, 3, 10, 1, 34, 4, 1, 23, 26, 41, 44, 26, 26, 35, 1, 52, 35, 36, 39, 34, 22, 33, 53, 1, 30, 35, 25, 30, 43, 30, 25, 42, 22, 33, 40, 1, 37, 22, 40, 40, 30, 35, 28, 1, 41, 29, 26, 1, 24, 22, 34, 26, 39, 22, 1, 22, 41, 1, 22, 1, 39, 22, 41, 26, 1, 36, 27, 1, 9, 1, 30, 35, 25, 30, 43, 30, 25, 42, 22, 33, 1, 37, 26, 39, 1, 40, 26, 24, 36, 35, 25, 5, 1, 44, 22, 40, 1, 25, 26, 41, 26, 24, 41, 26, 25, 1, 30, 35, 1, 16, 1, 36, 27, 1, 16, 1, 22, 41, 41, 26, 34, 37, 41, 40, 7, 1, 22, 25, 25, 30, 41, 30, 36, 35, 22, 33, 33, 46, 5, 1, 44, 29, 26, 35, 1, 41, 29, 26, 1, 27, 36, 39, 26, 29, 26, 22, 25, 1, 44, 22, 40, 1, 44, 22, 39, 34, 26, 25, 1, 22, 35, 25, 1, 41, 29, 26, 1, 44, 22, 39, 34, 26, 39, 1, 41, 29, 26, 35, 1, 39, 26, 34, 36, 43, 26, 25, 5, 1, 41, 29, 26, 1, 22, 41, 29, 26, 35, 22, 1, 40, 46, 40, 41, 26, 34, 1, 44, 22, 40, 1, 22, 23, 33, 26, 1, 41, 36, 1, 25, 26, 41, 26, 24, 41, 1, 41, 26, 34, 37, 26, 39, 22, 41, 42, 39, 26, 40, 1, 36, 27, 1, 19, 17, 17, 48, 27, 1, 36, 39, 1, 11, 15, 7, 10, 48, 24, 1, 3, 27, 30, 28, 7, 1, 9, 4, 1, 30, 35, 1, 13, 1, 36, 27, 1, 13, 1, 22, 41, 41, 26, 34, 37, 41, 40, 7, 1, 0, 0, 1, 40, 24, 39, 26, 26, 35, 26, 39, 40, 1, 42, 40, 30, 35, 28, 1, 41, 22, 41, 6, 13, 8, 8, 8, 40, 1, 41, 36, 36, 32, 1, 22, 1, 34, 26, 25, 30, 22, 35, 1, 36, 27, 1, 9, 14, 7, 13, 1, 40, 26, 24, 36, 35, 25, 40, 1, 27, 39, 36, 34, 1, 41, 29, 26, 1, 40, 41, 22, 39, 41, 1, 36, 27, 1, 41, 22, 32, 30, 35, 28, 1, 41, 29, 26, 1, 41, 26, 34, 37, 26, 39, 22, 41, 42, 39, 26, 1, 41, 29, 39, 36, 42, 28, 29, 1, 24, 33, 26, 22, 35, 30, 35, 28, 1, 41, 29, 26, 1, 25, 26, 43, 30, 24, 26, 1, 42, 35, 41, 30, 33, 1, 41, 29, 26, 1, 41, 29, 26, 39, 34, 36, 34, 26, 41, 26, 39, 1, 44, 22, 40, 1, 39, 26, 22, 25, 46, 1, 22, 28, 22, 30, 35, 7, 1, 41, 29, 26, 1, 22, 41, 29, 26, 35, 22, 1, 40, 46, 40, 41, 26, 34, 1, 29, 22, 40, 1, 35, 36, 1, 26, 27, 27, 26, 24, 41, 30, 43, 26, 1, 25, 26, 33, 22, 46, 1, 27, 39, 36, 34, 1, 37, 26, 39, 40, 36, 35, 1, 41, 36, 1, 37, 26, 39, 40, 36, 35, 1, 37, 22, 40, 40, 30, 35, 28, 1, 30, 35, 1, 22, 1, 40, 30, 35, 28, 33, 26, 6, 27, 30, 33, 26, 1, 33, 30, 35, 26, 7, 1, 41, 29, 26, 1, 24, 36, 43, 30, 25, 6, 9, 17, 1, 37, 22, 35, 25, 26, 34, 30, 24, 1, 29, 22, 40, 1, 33, 26, 25, 1, 41, 36, 1, 41, 29, 26, 1, 30, 34, 37, 33, 26, 34, 26, 35, 41, 22, 41, 30, 36, 35, 1, 36, 27, 1, 41, 26, 34, 37, 26, 39, 22, 41, 42, 39, 26, 1, 40, 24, 39, 26, 26, 35, 30, 35, 28, 1, 30, 35, 1, 22, 1, 44, 30, 25, 26, 1, 43, 22, 39, 30, 26, 41, 46, 1, 36, 27, 1, 27, 22, 24, 30, 33, 30, 41, 30, 26, 40, 7, 1, 22, 33, 41, 29, 36, 42, 28, 29, 1, 41, 26, 34, 37, 26, 39, 22, 41, 42, 39, 26, 1, 40, 24, 39, 26, 26, 35, 30, 35, 28, 1, 29, 22, 40, 1, 23, 26, 26, 35, 1, 42, 40, 26, 25, 1, 30, 35, 1, 37, 42, 23, 33, 30, 24, 1, 40, 26, 41, 41, 30, 35, 28, 40, 1, 25, 42, 39, 30, 35, 28, 1, 37, 39, 26, 43, 30, 36, 42, 40, 1, 30, 35, 27, 26, 24, 41, 30, 36, 42, 40, 1, 25, 30, 40, 26, 22, 40, 26, 40, 1, 36, 42, 41, 23, 39, 26, 22, 32, 40, 5, 14, 50, 16, 1, 41, 29, 26, 1, 42, 40, 26, 27, 42, 33, 35, 26, 40, 40, 1, 36, 27, 1, 41, 26, 34, 37, 26, 39, 22, 41, 42, 39, 26, 1, 40, 24, 39, 26, 26, 35, 30, 35, 28, 1, 41, 36, 1, 25, 26, 41, 26, 24, 41, 1, 37, 36, 41, 26, 35, 41, 30, 22, 33, 1, 30, 35, 27, 26, 24, 41, 30, 36, 35, 40, 1, 29, 22, 40, 1, 23, 26, 26, 35, 1, 38, 42, 26, 40, 41, 30, 36, 35, 26, 25, 7, 14, 5, 15, 1, 29, 36, 44, 26, 43, 26, 39, 5, 1, 41, 26, 34, 37, 26, 39, 22, 41, 42, 39, 26, 1, 40, 24, 39, 26, 26, 35, 30, 35, 28, 1, 34, 22, 46, 1, 25, 30, 40, 24, 36, 42, 39, 22, 28, 26, 1, 40, 46, 34, 37, 41, 36, 34, 22, 41, 30, 24, 1, 30, 35, 25, 30, 43, 30, 25, 42, 22, 33, 40, 1, 27, 39, 36, 34, 1, 26, 35, 41, 26, 39, 30, 35, 28, 1, 37, 42, 23, 33, 30, 24, 1, 37, 33, 22, 24, 26, 40, 1, 22, 35, 25, 1, 34, 22, 46, 1, 30, 35, 24, 39, 26, 22, 40, 26, 1, 24, 36, 34, 27, 36, 39, 41, 1, 27, 36, 39, 1, 29, 26, 22, 33, 41, 29, 46, 1, 37, 26, 36, 37, 33, 26, 7, 16, 0, 1, 36, 42, 39, 1, 40, 41, 42, 25, 46, 1, 42, 40, 30, 35, 28, 1, 35, 36, 35, 30, 35, 43, 22, 40, 30, 43, 26, 1, 25, 26, 43, 30, 24, 26, 40, 1, 44, 22, 40, 1, 35, 36, 41, 1, 25, 26, 40, 30, 28, 35, 26, 25, 1, 41, 36, 1, 41, 26, 40, 41, 1, 41, 29, 26, 1, 22, 24, 24, 42, 39, 22, 24, 46, 1, 36, 27, 1, 25, 26, 43, 30, 24, 26, 40, 5, 1, 41, 29, 36, 42, 28, 29, 1, 41, 26, 34, 37, 36, 39, 22, 33, 1, 40, 24, 22, 35, 35, 26, 39, 40, 1, 22, 39, 26, 1, 44, 30, 25, 26, 33, 46, 1, 24, 36, 35, 40, 30, 25, 26, 39, 26, 25, 1, 39, 26, 33, 30, 22, 23, 33, 26, 1, 26, 35, 36, 42, 28, 29, 1, 27, 36, 39, 1, 37, 39, 36, 27, 26, 40, 40, 30, 36, 35, 22, 33, 1, 42, 40, 26, 7, 17, 5, 9, 8, 1, 30, 35, 1, 36, 42, 39, 1, 42, 40, 26, 5, 1, 41, 26, 34, 37, 26, 39, 22, 41, 42, 39, 26, 40, 1, 34, 26, 22, 40, 42, 39, 26, 25, 1, 23, 46, 1, 41, 26, 33, 26, 41, 29, 26, 39, 34, 36, 28, 39, 22, 37, 29, 30, 24, 1, 40, 46, 40, 41, 26, 34, 40, 1, 44, 26, 39, 26, 1, 40, 30, 34, 30, 33, 22, 39, 1, 41, 36, 1, 41, 29, 36, 40, 26, 1, 36, 23, 41, 22, 30, 35, 26, 25, 1, 23, 46, 1, 41, 26, 34, 37, 36, 39, 22, 33, 1, 40, 24, 22, 35, 35, 26, 39, 40, 5, 1, 40, 42, 28, 28, 26, 40, 41, 30, 35, 28, 1, 40, 30, 34, 30, 33, 22, 39, 1, 37, 26, 39, 27, 36, 39, 34, 22, 35, 24, 26, 7, 1, 24, 36, 40, 41, 1, 30, 40, 1, 41, 29, 26, 1, 23, 30, 28, 28, 26, 40, 41, 1, 23, 22, 39, 39, 30, 26, 39, 1, 41, 36, 1, 30, 34, 37, 33, 26, 34, 26, 35, 41, 22, 41, 30, 36, 35, 1, 27, 36, 39, 1, 41, 26, 33, 26, 41, 29, 26, 39, 34, 36, 28, 39, 22, 37, 29, 30, 24, 1, 40, 46, 40, 41, 26, 34, 40, 7, 1, 27, 36, 39, 1, 36, 42, 39, 1, 30, 35, 43, 26, 40, 41, 34, 26, 35, 41, 1, 39, 26, 24, 36, 43, 26, 39, 46, 1, 22, 35, 22, 33, 46, 40, 30, 40, 5, 1, 44, 26, 1, 24, 36, 35, 40, 30, 25, 26, 39, 26, 25, 1, 41, 42, 39, 35, 22, 39, 36, 42, 35, 25, 1, 41, 30, 34, 26, 1, 25, 30, 27, 27, 26, 39, 26, 35, 24, 26, 1, 23, 26, 41, 44, 26, 26, 35, 1, 41, 26, 34, 37, 36, 39, 22, 33, 1, 40, 24, 22, 35, 35, 26, 39, 40, 1, 22, 35, 25, 1, 22, 1, 41, 29, 26, 39, 34, 22, 33, 1, 24, 22, 34, 26, 39, 22, 1, 27, 36, 39, 1, 26, 22, 24, 29, 1, 40, 24, 39, 26, 26, 35, 26, 25, 1, 30, 35, 25, 30, 43, 30, 25, 42, 22, 33, 1, 22, 41, 1, 22, 1, 29, 30, 28, 29, 6, 26, 35, 41, 39, 46, 1, 33, 36, 24, 22, 41, 30, 36, 35, 1, 44, 30, 41, 29, 1, 33, 22, 39, 28, 26, 1, 28, 39, 36, 42, 37, 40, 1, 22, 39, 39, 30, 43, 30, 35, 28, 1, 30, 35, 1, 22, 1, 40, 29, 36, 39, 41, 1, 37, 26, 39, 30, 36, 25, 5, 1, 25, 26, 40, 30, 39, 26, 25, 1, 41, 29, 39, 36, 42, 28, 29, 37, 42, 41, 1, 39, 22, 41, 26, 1, 36, 27, 1, 9, 1, 37, 26, 39, 40, 36, 35, 1, 37, 26, 39, 1, 40, 26, 24, 36, 35, 25, 5, 1, 34, 22, 30, 35, 41, 22, 30, 35, 30, 35, 28, 1, 14, 6, 27, 26, 26, 41, 1, 3, 10, 6, 34, 4, 1, 40, 36, 24, 30, 22, 33, 1, 25, 30, 40, 41, 22, 35, 24, 30, 35, 28, 1, 22, 35, 25, 1, 40, 30, 35, 28, 33, 26, 6, 27, 30, 33, 26, 1, 33, 30, 35, 26, 40, 1, 27, 36, 39, 1, 30, 35, 25, 30, 43, 30, 25, 42, 22, 33, 1, 40, 46, 34, 37, 41, 36, 34, 1, 40, 24, 39, 26, 26, 35, 30, 35, 28, 7, 1, 44, 26, 1, 26, 40, 41, 30, 34, 22, 41, 26, 25, 1, 35, 26, 26, 25, 30, 35, 28, 1, 14, 1, 41, 26, 34, 37, 36, 39, 22, 33, 1, 40, 24, 22, 35, 35, 26, 39, 1, 36, 37, 26, 39, 22, 41, 36, 39, 40, 1, 27, 36, 39, 1, 26, 43, 26, 39, 46, 1, 9, 1, 41, 29, 26, 39, 34, 22, 33, 1, 24, 22, 34, 26, 39, 22, 1, 36, 37, 26, 39, 22, 41, 36, 39, 7, 1, 44, 30, 41, 29, 1, 36, 42, 39, 1, 36, 39, 28, 22, 35, 30, 47, 22, 41, 30, 36, 35, 51, 40, 1, 25, 30, 39, 26, 24, 41, 1, 33, 22, 23, 36, 39, 1, 39, 22, 41, 26, 40, 1, 22, 35, 25, 1, 36, 43, 26, 39, 29, 26, 22, 25, 1, 24, 36, 40, 41, 40, 5, 1, 30, 35, 43, 26, 40, 41, 34, 26, 35, 41, 1, 39, 26, 24, 36, 43, 26, 39, 46, 1, 44, 22, 40, 1, 26, 40, 41, 30, 34, 22, 41, 26, 25, 1, 41, 36, 1, 36, 24, 24, 42, 39, 1, 30, 35, 1, 34, 36, 35, 41, 29, 40, 5, 1, 33, 26, 22, 25, 30, 35, 28, 1, 41, 36, 1, 22, 25, 36, 37, 41, 30, 36, 35, 1, 36, 27, 1, 12, 1, 41, 26, 33, 26, 41, 29, 26, 39, 34, 36, 28, 39, 22, 37, 29, 30, 24, 1, 40, 46, 40, 41, 26, 34, 40, 1, 22, 41, 1, 36, 42, 39, 1, 10, 1, 29, 30, 28, 29, 26, 40, 41, 6, 26, 35, 41, 39, 46, 1, 33, 36, 24, 22, 41, 30, 36, 35, 40, 7, 1, 44, 26, 1, 39, 26, 25, 42, 24, 26, 25, 1, 40, 24, 39, 26, 26, 35, 30, 35, 28, 1, 40, 41, 22, 27, 27, 1, 27, 39, 36, 34, 1, 10, 12, 1, 41, 36, 1, 12, 1, 30, 35, 25, 30, 43, 30, 25, 42, 22, 33, 40, 5, 1, 22, 35, 25, 1, 41, 29, 26, 39, 26, 1, 22, 39, 26, 1, 35, 36, 44, 1, 35, 36, 1, 44, 22, 30, 41, 30, 35, 28, 1, 33, 30, 35, 26, 40, 1, 22, 41, 1, 41, 29, 26, 40, 26, 1, 33, 36, 24, 22, 41, 30, 36, 35, 40, 7, 1, 30, 35, 1, 24, 36, 35, 24, 33, 42, 40, 30, 36, 35, 5, 1, 36, 42, 39, 1, 26, 45, 37, 26, 39, 30, 26, 35, 24, 26, 1, 25, 26, 34, 36, 35, 40, 41, 39, 22, 41, 26, 40, 1, 41, 29, 22, 41, 1, 22, 1, 41, 26, 33, 26, 41, 29, 26, 39, 34, 36, 28, 39, 22, 37, 29, 30, 24, 1, 40, 46, 40, 41, 26, 34, 1, 30, 34, 37, 39, 36, 43, 26, 40, 1, 40, 24, 39, 26, 26, 35, 30, 35, 28, 1, 41, 29, 39, 36, 42, 28, 29, 37, 42, 41, 1, 22, 35, 25, 1, 39, 26, 37, 36, 39, 41, 40, 1, 41, 26, 34, 37, 26, 39, 22, 41, 42, 39, 26, 40, 1, 40, 30, 34, 30, 33, 22, 39, 1, 41, 36, 1, 41, 29, 36, 40, 26, 1, 39, 26, 24, 36, 39, 25, 26, 25, 1, 23, 46, 1, 41, 26, 34, 37, 36, 39, 22, 33, 1, 40, 24, 22, 35, 35, 26, 39, 40, 5, 1, 44, 30, 41, 29, 1, 22, 24, 24, 26, 37, 41, 22, 23, 33, 26, 1, 30, 35, 43, 26, 40, 41, 34, 26, 35, 41, 1, 39, 26, 24, 36, 43, 26, 39, 46, 1, 41, 30, 34, 26, 7]\n","Seed:\n","\" tic” individual in single-file line 6 feet (2 m) between “normal” individuals passing the camera at  \"\n","a rate oo 1 individnal ser eeccc tecdtedn with the aacerate fo a secenae ie 1 ou a 55% ii, 0.24–0.56) or 0.22°c (95% ci, 0.11–0.21)]. during the tet-5000s measured temperatures significcnt dideee tee tee athena system amean difference bntween temperature screening th temperature screening tas sete ou mhssieent dnd eevereeeee  dos ss ree figenanee io teneleerer thrh rhe sareenerg oo theseon with the aacerate fo a beccrt to the facera bo a sate oo 1 individnen  whe athena system war aecen to too athena securiry  aue axhena securiry  aue axhena securiry  aue axhena securiry  aue axhena securiry  aue axhena securiry  aue axhena securiry  aue axhena securiry  aue axhena securiry  aue axhena securiry  aue axhena securiry  aue axhena securiry  aue axhena securiry  aue axhena securiry  aue axhena securiry  aue axhena securiry  aue axhena securiry  aue axhena securiry  aue axhena securiry  aue axhena securiry  aue axhena securiry  aue axhena securiry  aue axhena securiry  aue axhena securiry  a\n","Done.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"3XrpAtCmhNhT"},"source":[""]},{"cell_type":"code","metadata":{"id":"jQKqyK8bhOAF"},"source":["# to add -\n","\n","\n","ascii_values = ascii_values[np.where(ascii_values < 128)]"],"execution_count":null,"outputs":[]}]}